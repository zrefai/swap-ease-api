{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face</th>\n",
       "      <th>hair</th>\n",
       "      <th>body</th>\n",
       "      <th>background</th>\n",
       "      <th>head</th>\n",
       "      <th>trait_count</th>\n",
       "      <th>piercing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9659</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.417033</td>\n",
       "      <td>1.358327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7573</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.417033</td>\n",
       "      <td>1.358327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.417033</td>\n",
       "      <td>1.358327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>42.194093</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.417033</td>\n",
       "      <td>1.358327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9243</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>32.679739</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.417033</td>\n",
       "      <td>1.358327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         face       hair     body background     head trait_count  piercing\n",
       "9659  10000.0    10000.0  10000.0    10000.0  10000.0    1.417033  1.358327\n",
       "7573  10000.0    10000.0  10000.0    10000.0  10000.0    1.417033  1.358327\n",
       "2912  10000.0    10000.0  10000.0    10000.0  10000.0    1.417033  1.358327\n",
       "2560  10000.0    10000.0  10000.0  42.194093  10000.0    1.417033  1.358327\n",
       "9243  10000.0  32.679739  10000.0    10000.0  10000.0    1.417033  1.358327"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read the data\n",
    "def load_data(file_name):\n",
    "    with open(file_name) as f:\n",
    "        ds = json.load(f)\n",
    "\n",
    "    columns = ds['columns']\n",
    "    distributions = ds['distributions']\n",
    "    indexes = []\n",
    "\n",
    "    for distribution in distributions:\n",
    "        indexes.append(distribution['tokenId'])\n",
    "\n",
    "    data = pd.DataFrame(columns=[*columns], index=indexes)\n",
    "\n",
    "    for index, token in enumerate(data.index):\n",
    "        data.loc[token] = distributions[index]['totalScoreDistribution']\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = load_data('../score_distributions/DOODLES_totalScoreDistribution.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(<function train_test_split at 0x13f7225e0>, dtype=object) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[39m=\u001b[39m RandomForestRegressor(random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m      5\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mget_dummies(data)\n\u001b[0;32m----> 6\u001b[0m model\u001b[39m.\u001b[39;49mfit(data, train_test_split)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/ensemble/_forest.py:331\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[1;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 331\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    332\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[1;32m    333\u001b[0m )\n\u001b[1;32m    334\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py:1090\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[1;32m   1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[0;32m-> 1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric, estimator\u001b[39m=\u001b[39;49mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1094\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py:1100\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m multi_output:\n\u001b[0;32m-> 1100\u001b[0m     y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1101\u001b[0m         y,\n\u001b[1;32m   1102\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1103\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1104\u001b[0m         ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1105\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1106\u001b[0m         input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1107\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1108\u001b[0m     )\n\u001b[1;32m   1109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1110\u001b[0m     estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py:907\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    899\u001b[0m         _assert_all_finite(\n\u001b[1;32m    900\u001b[0m             array,\n\u001b[1;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[1;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[1;32m    909\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    910\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    913\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py:325\u001b[0m, in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m x\u001b[39m.\u001b[39mshape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 325\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    326\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSingleton array \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m cannot be considered a valid collection.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m x\n\u001b[1;32m    327\u001b[0m         )\n\u001b[1;32m    328\u001b[0m     \u001b[39m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[39m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], numbers\u001b[39m.\u001b[39mIntegral):\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array array(<function train_test_split at 0x13f7225e0>, dtype=object) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = RandomForestRegressor(random_state=1, max_depth=10)\n",
    "data = pd.get_dummies(data)\n",
    "# model.fit(data, train_test_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
